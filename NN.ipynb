{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from pandas import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = np.arange(10)\n",
    "activation_names = ['relu64', 'relu128', 'selu64', 'selu128', 'tanh64', 'tanh128', 'sigmoid64', 'sigmoid128', 'elu64', 'elu128', 'linear64', 'linear128']\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Preprocess the data (these are Numpy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype('float32') / 255\n",
    "x_test = x_test.reshape(10000, 784).astype('float32') / 255\n",
    "\n",
    "y_train = y_train.astype('float32')\n",
    "y_test = y_test.astype('float32')\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "\n",
    "# NN model combination array\n",
    "models = [keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "        keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(128, activation=\"relu\"),\n",
    "    keras.layers.Dense(10)\n",
    "]),\n",
    "         keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(64, activation=\"selu\"),\n",
    "    keras.layers.Dense(64, activation=\"selu\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "        keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(128, activation=\"selu\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "         keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(64, activation=\"tanh\"),\n",
    "    keras.layers.Dense(64, activation=\"tanh\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "        keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(128, activation=\"tanh\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "         keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(64, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(64, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "        keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(128, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "         keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(64, activation=\"elu\"),\n",
    "    keras.layers.Dense(64, activation=\"elu\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "        keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(128, activation=\"elu\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "         keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(64, activation=\"linear\"),\n",
    "    keras.layers.Dense(64, activation=\"linear\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "        keras.Sequential([\n",
    "    keras.layers.Input(shape=(784,)),\n",
    "    keras.layers.Dense(128, activation=\"linear\"),\n",
    "    keras.layers.Dense(10,)\n",
    "]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "# Fit model on training data with Dense activation:  relu64\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3049 - sparse_categorical_accuracy: 0.9104 - val_loss: 0.1643 - val_sparse_categorical_accuracy: 0.9524\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1420 - sparse_categorical_accuracy: 0.9573 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9639\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1026 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.1202 - val_sparse_categorical_accuracy: 0.9669\n\n# Evaluate on test data\n313/313 [==============================] - 0s 1ms/step - loss: 0.1143 - sparse_categorical_accuracy: 0.9653\n\ntest loss, test acc: [0.11432377249002457, 0.9653000235557556]\n\n# Fit model on training data with Dense activation:  relu128\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.2794 - sparse_categorical_accuracy: 0.9198 - val_loss: 0.1478 - val_sparse_categorical_accuracy: 0.9580\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.1115 - val_sparse_categorical_accuracy: 0.9684\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.0972 - sparse_categorical_accuracy: 0.9716 - val_loss: 0.1054 - val_sparse_categorical_accuracy: 0.9716\n\n# Evaluate on test data\n313/313 [==============================] - 0s 1ms/step - loss: 0.1042 - sparse_categorical_accuracy: 0.9710\n\ntest loss, test acc: [0.10421281307935715, 0.9710000157356262]\n\n# Fit model on training data with Dense activation:  selu64\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3232 - sparse_categorical_accuracy: 0.9034 - val_loss: 0.1997 - val_sparse_categorical_accuracy: 0.9439\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1711 - sparse_categorical_accuracy: 0.9482 - val_loss: 0.1480 - val_sparse_categorical_accuracy: 0.9562\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1273 - sparse_categorical_accuracy: 0.9617 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9597\n\n# Evaluate on test data\n313/313 [==============================] - 0s 1ms/step - loss: 0.1361 - sparse_categorical_accuracy: 0.9578\n\ntest loss, test acc: [0.13610927760601044, 0.9577999711036682]\n\n# Fit model on training data with Dense activation:  selu128\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3388 - sparse_categorical_accuracy: 0.9015 - val_loss: 0.2252 - val_sparse_categorical_accuracy: 0.9372\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.2016 - sparse_categorical_accuracy: 0.9411 - val_loss: 0.1517 - val_sparse_categorical_accuracy: 0.9585\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1397 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.1217 - val_sparse_categorical_accuracy: 0.9644\n\n# Evaluate on test data\n313/313 [==============================] - 0s 1ms/step - loss: 0.1248 - sparse_categorical_accuracy: 0.9639\n\ntest loss, test acc: [0.12480610609054565, 0.9639000296592712]\n\n# Fit model on training data with Dense activation:  tanh64\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3078 - sparse_categorical_accuracy: 0.9116 - val_loss: 0.1784 - val_sparse_categorical_accuracy: 0.9507\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1558 - sparse_categorical_accuracy: 0.9530 - val_loss: 0.1583 - val_sparse_categorical_accuracy: 0.9530\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1144 - sparse_categorical_accuracy: 0.9654 - val_loss: 0.1137 - val_sparse_categorical_accuracy: 0.9660\n\n# Evaluate on test data\n313/313 [==============================] - 1s 2ms/step - loss: 0.1137 - sparse_categorical_accuracy: 0.9671\n\ntest loss, test acc: [0.11371417343616486, 0.9671000242233276]\n\n# Fit model on training data with Dense activation:  tanh128\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3023 - sparse_categorical_accuracy: 0.9127 - val_loss: 0.1840 - val_sparse_categorical_accuracy: 0.9475\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1587 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.1307 - val_sparse_categorical_accuracy: 0.9620\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9667 - val_loss: 0.1086 - val_sparse_categorical_accuracy: 0.9680\n\n# Evaluate on test data\n313/313 [==============================] - 1s 2ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9669\n\ntest loss, test acc: [0.10666899383068085, 0.9668999910354614]\n\n# Fit model on training data with Dense activation:  sigmoid64\nEpoch 1/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.5800 - sparse_categorical_accuracy: 0.8507 - val_loss: 0.2447 - val_sparse_categorical_accuracy: 0.9297\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.2284 - sparse_categorical_accuracy: 0.9318 - val_loss: 0.1795 - val_sparse_categorical_accuracy: 0.9487\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1749 - sparse_categorical_accuracy: 0.9483 - val_loss: 0.1489 - val_sparse_categorical_accuracy: 0.9564\n\n# Evaluate on test data\n313/313 [==============================] - 0s 2ms/step - loss: 0.1594 - sparse_categorical_accuracy: 0.9519\n\ntest loss, test acc: [0.1594342291355133, 0.9519000053405762]\n\n# Fit model on training data with Dense activation:  sigmoid128\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.4055 - sparse_categorical_accuracy: 0.8920 - val_loss: 0.2265 - val_sparse_categorical_accuracy: 0.9336\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.2134 - sparse_categorical_accuracy: 0.9376 - val_loss: 0.1783 - val_sparse_categorical_accuracy: 0.9482\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1658 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.1463 - val_sparse_categorical_accuracy: 0.9588\n\n# Evaluate on test data\n313/313 [==============================] - 0s 2ms/step - loss: 0.1496 - sparse_categorical_accuracy: 0.9551\n\ntest loss, test acc: [0.14964832365512848, 0.9550999999046326]\n\n# Fit model on training data with Dense activation: elu64\nEpoch 1/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.3077 - sparse_categorical_accuracy: 0.9091 - val_loss: 0.1761 - val_sparse_categorical_accuracy: 0.9490\nEpoch 2/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9529 - val_loss: 0.1343 - val_sparse_categorical_accuracy: 0.9596\nEpoch 3/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.1167 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.1145 - val_sparse_categorical_accuracy: 0.9670\n\n# Evaluate on test data\n313/313 [==============================] - 1s 2ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9647\n\ntest loss, test acc: [0.12064158171415329, 0.9646999835968018]\n\n# Fit model on training data with Dense activation:  elu128\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3198 - sparse_categorical_accuracy: 0.9078 - val_loss: 0.1853 - val_sparse_categorical_accuracy: 0.9492\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1684 - sparse_categorical_accuracy: 0.9503 - val_loss: 0.1476 - val_sparse_categorical_accuracy: 0.9571\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.1214 - sparse_categorical_accuracy: 0.9640 - val_loss: 0.1154 - val_sparse_categorical_accuracy: 0.9657\n\n# Evaluate on test data\n313/313 [==============================] - 0s 2ms/step - loss: 0.1207 - sparse_categorical_accuracy: 0.9643\n\ntest loss, test acc: [0.12070667743682861, 0.9642999768257141]\n\n# Fit model on training data with Dense activation:  linear64\nEpoch 1/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.3817 - sparse_categorical_accuracy: 0.8904 - val_loss: 0.3001 - val_sparse_categorical_accuracy: 0.9146\nEpoch 2/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.3184 - sparse_categorical_accuracy: 0.9095 - val_loss: 0.3165 - val_sparse_categorical_accuracy: 0.9127\nEpoch 3/3\n1563/1563 [==============================] - 5s 3ms/step - loss: 0.3075 - sparse_categorical_accuracy: 0.9143 - val_loss: 0.3338 - val_sparse_categorical_accuracy: 0.9077\n\n# Evaluate on test data\n313/313 [==============================] - 0s 2ms/step - loss: 0.3586 - sparse_categorical_accuracy: 0.9025\n\ntest loss, test acc: [0.3585517704486847, 0.9024999737739563]\n\n# Fit model on training data with Dense activation: linear128\nEpoch 1/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3731 - sparse_categorical_accuracy: 0.8953 - val_loss: 0.2867 - val_sparse_categorical_accuracy: 0.9211\nEpoch 2/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3129 - sparse_categorical_accuracy: 0.9135 - val_loss: 0.2818 - val_sparse_categorical_accuracy: 0.9224\nEpoch 3/3\n1563/1563 [==============================] - 4s 3ms/step - loss: 0.3014 - sparse_categorical_accuracy: 0.9169 - val_loss: 0.2794 - val_sparse_categorical_accuracy: 0.9250\n\n# Evaluate on test data\n313/313 [==============================] - 0s 2ms/step - loss: 0.2916 - sparse_categorical_accuracy: 0.9194\n\ntest loss, test acc: [0.2915778160095215, 0.9193999767303467]\n\n                loss  accuracy\nrelu64      0.114324    0.9653\nrelu128     0.104213    0.9710\nselu64      0.136109    0.9578\nselu128     0.124806    0.9639\ntanh64      0.113714    0.9671\ntanh128     0.106669    0.9669\nsigmoid64   0.159434    0.9519\nsigmoid128  0.149648    0.9551\nelu64       0.120642    0.9647\nelu128      0.120707    0.9643\nlinear64    0.358552    0.9025\nlinear128   0.291578    0.9194\n"
    }
   ],
   "source": [
    "results=[]\n",
    "i=0\n",
    "for model in models:\n",
    "    model.compile(optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "              # Loss function to minimize\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              # List of metrics to monitor\n",
    "              metrics=['sparse_categorical_accuracy'])\n",
    "    print('# Fit model on training data with Dense activation: ', activation_names[i])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        epochs=3,\n",
    "                        # We pass some validation for\n",
    "                        # monitoring validation loss and metrics\n",
    "                        # at the end of each epoch\n",
    "                        validation_data=(x_val, y_val))\n",
    "\n",
    "    #print('\\nhistory dict:', history.history)\n",
    "    \n",
    "    # Evaluate the model on the test data using `evaluate`\n",
    "    print('\\n# Evaluate on test data')\n",
    "    results.append(model.evaluate(x_test, y_test))\n",
    "    print('\\ntest loss, test acc:', results[i])\n",
    "    i+=1\n",
    "    print()\n",
    "print(DataFrame(results, index=activation_names, columns=['loss','accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38164bit6cfe0cbd144c4361a6502b3bbb40a00c",
   "display_name": "Python 3.8.1 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}